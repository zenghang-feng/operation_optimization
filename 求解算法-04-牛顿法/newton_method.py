import sympy as sp

#################################################################
# 定义目标函数，并计算hessian矩阵特征值
#################################################################
# 定义变量、函数 ===================================================
x, y = sp.symbols(["x", "y"])
f_xy = x**4 + 0.8 * y**4 + 4 * x**2 + 2 * y**2 - x * y - 0.2 * x ** 2 * y

#################################################################
# 牛顿法求极值
#################################################################
# 初始化选择一个点 =================================================
vec_k = sp.Matrix([5, 6])
point_list = []
point_list.append(vec_k)

# 定义用于判断终止条件的误差 =========================================
error = 0.001
f_dif = 100

# 计算梯度和hessian矩阵 ============================================
grad = sp.Matrix([sp.diff(f_xy, x), sp.diff(f_xy, y)])       # 计算梯度
hessian = sp.hessian(f_xy, varlist=[x, y])                                    # 计算Hessian矩阵

# 开始进行迭代 ====================================================
c = 0
while f_dif > error:
    x_k = vec_k[0, 0]
    y_k = vec_k[1, 0]
    f_xy_k_val = f_xy.subs([(x, x_k), (y, y_k)])

    grad_val = grad.subs([(x, x_k), (y, y_k)])
    hessian_val = hessian.subs([(x, x_k), (y, y_k)])
    hessian_val_inv = hessian_val.inv()
    vec_k1 = vec_k - hessian_val_inv * grad_val

    x_k1 = vec_k1[0,0]
    y_k1 = vec_k1[1,0]
    f_xy_k1_val = f_xy.subs([(x,x_k1), (y,y_k1)])

    f_dif = abs(f_xy_k_val-f_xy_k1_val)
    vec_k = vec_k1

    c += 1
    print(c, "次迭代")

#################################################################
# 计算特征值，判断是极大值还是极小值 ==================================
#################################################################
eigen_values = hessian_val.eigenvals()
# 特征值均为正数，所以极值点是极小值

